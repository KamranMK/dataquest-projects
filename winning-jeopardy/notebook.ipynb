{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for a few decades, and is a major force in popular culture. \n",
    "\n",
    "Let's say we want to compete on Jeopardy, and we're looking for any edge we can get to win. In this project, we'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help us win.\n",
    "\n",
    "**Project Goal**\n",
    "In this project, we'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help us win.\n",
    "\n",
    "This project is part of the guided project series on [dataquest](http://dataquest.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeopardy Questions\n",
    "\n",
    "Let's explore the jeopardy questions. We will see that the dataset contains the following columns:\n",
    "\n",
    "* `Show Number` -- the Jeopardy episode number of the show this question was in.\n",
    "* `Air Date` -- the date the episode aired.\n",
    "* `Round` -- the round of Jeopardy that the question was asked in. Jeopardy has several rounds as each episode progresses.\n",
    "* `Category` -- the category of the question.\n",
    "* `Value` -- the number of dollars answering the question correctly is worth.\n",
    "* `Question` -- the text of the question.\n",
    "* `Answer` -- the text of the answer.\n",
    "\n",
    "Let's start our exploration with loading data in and reviewing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import re\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# read in the dataset\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the names of each column contain an additional space. Let's remove those and keep the name only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ShowNumber', 'AirDate', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean column names from additional spaces\n",
    "jeopardy.columns = jeopardy.columns.str.replace(' ', '')\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 7)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShowNumber</th>\n",
       "      <th>AirDate</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShowNumber     AirDate      Round                         Category Value  \\\n",
       "0        4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1        4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2        4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3        4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4        4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains 216930 questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Text\n",
    "\n",
    "Before we start with our analysis, we need to normalize the text, that is ensure lowercase words and remove punctuation. There are two ways we can go about this. Let's see which one is more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.93 µs ± 266 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "4.63 µs ± 460 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# function to normalize the text using python string library\n",
    "def normalize_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = s.translate(str.maketrans('', '', punctuation))\n",
    "    return s\n",
    "\n",
    "# function to normalize the text using regex\n",
    "def normalize_text_reg(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(\"[^A-Za-z0-9\\s]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "s = 'Hello.?! World.*'\n",
    "%timeit normalize_text(s)\n",
    "%timeit normalize_text_reg(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that using the function with regular expression seems to be much faster. We will use it to treat and normalize our `Question` and `Answer` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize our columns\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text_reg)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShowNumber</th>\n",
       "      <th>AirDate</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "      <th>answer_in_question</th>\n",
       "      <th>question_overlap</th>\n",
       "      <th>high_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19325</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>U.S. PRESIDENTS</td>\n",
       "      <td>None</td>\n",
       "      <td>Adventurous 26th president, he was 1st to ride...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>adventurous 26th president he was 1st to ride ...</td>\n",
       "      <td>theodore roosevelt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>LABOR UNIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Notorious labor leader missing since '75</td>\n",
       "      <td>Jimmy Hoffa</td>\n",
       "      <td>notorious labor leader missing since 75</td>\n",
       "      <td>jimmy hoffa</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>1789</td>\n",
       "      <td>$200</td>\n",
       "      <td>Washington proclaimed Nov. 26, 1789 this first...</td>\n",
       "      <td>Thanksgiving</td>\n",
       "      <td>washington proclaimed nov 26 1789 this first n...</td>\n",
       "      <td>thanksgiving</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>TOURIST TRAPS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Both Ferde Grofe' &amp; the Colorado River dug thi...</td>\n",
       "      <td>the Grand Canyon</td>\n",
       "      <td>both ferde grofe  the colorado river dug this ...</td>\n",
       "      <td>the grand canyon</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>$200</td>\n",
       "      <td>Depending on the book, he could be a \"Jones\", ...</td>\n",
       "      <td>Tom</td>\n",
       "      <td>depending on the book he could be a jones a sa...</td>\n",
       "      <td>tom</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ShowNumber    AirDate             Round         Category Value  \\\n",
       "19325          10 1984-09-21   Final Jeopardy!  U.S. PRESIDENTS  None   \n",
       "19301          10 1984-09-21  Double Jeopardy!     LABOR UNIONS  $200   \n",
       "19302          10 1984-09-21  Double Jeopardy!             1789  $200   \n",
       "19303          10 1984-09-21  Double Jeopardy!    TOURIST TRAPS  $200   \n",
       "19304          10 1984-09-21  Double Jeopardy!       LITERATURE  $200   \n",
       "\n",
       "                                                Question              Answer  \\\n",
       "19325  Adventurous 26th president, he was 1st to ride...  Theodore Roosevelt   \n",
       "19301           Notorious labor leader missing since '75         Jimmy Hoffa   \n",
       "19302  Washington proclaimed Nov. 26, 1789 this first...        Thanksgiving   \n",
       "19303  Both Ferde Grofe' & the Colorado River dug thi...    the Grand Canyon   \n",
       "19304  Depending on the book, he could be a \"Jones\", ...                 Tom   \n",
       "\n",
       "                                          clean_question        clean_answer  \\\n",
       "19325  adventurous 26th president he was 1st to ride ...  theodore roosevelt   \n",
       "19301            notorious labor leader missing since 75         jimmy hoffa   \n",
       "19302  washington proclaimed nov 26 1789 this first n...        thanksgiving   \n",
       "19303  both ferde grofe  the colorado river dug this ...    the grand canyon   \n",
       "19304  depending on the book he could be a jones a sa...                 tom   \n",
       "\n",
       "       clean_value  answer_in_question  question_overlap  high_value  \n",
       "19325            0                 0.0               0.0           0  \n",
       "19301          200                 0.0               0.0           0  \n",
       "19302          200                 0.0               0.0           0  \n",
       "19303          200                 0.0               0.5           0  \n",
       "19304          200                 0.0               0.0           0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Columns\n",
    "\n",
    "Now that we have normalized the string columns, let's also normalize `Value` and `Air Date` columns. We will remove the $ sign from the `Value` column and convert the column to numeric; we will also convert `Air Date` to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to normalize value column \n",
    "def normalize_value(s):\n",
    "    s = re.sub(\"[^A-Za-z0-9\\s]\", \"\", s)\n",
    "    try:\n",
    "        s = int(s)\n",
    "    except:\n",
    "        s = 0\n",
    "    return s\n",
    "\n",
    "# clean value column\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_value)\n",
    "jeopardy['AirDate'] = pd.to_datetime(jeopardy['AirDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers in Questions\n",
    "\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "* How often the answer is deducible from the question.\n",
    "* How often new questions are repeats of older questions.\n",
    "\n",
    "We can answer the first question by seeing how many times words in the answer also occur in the question. We can answer the 2nd question by seeing how often complex words (> 6 characters) reoccur. Let's tackle the first question first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900196524977763"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to count words from answer in the question\n",
    "def count_terms(row):\n",
    "    # split the column values by space\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()    \n",
    "    \n",
    "    # initialize count of words\n",
    "    match_count = 0\n",
    "    \n",
    "    # remove 'the' from answers\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    \n",
    "    # check if answer is 0\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # count ocurrences of answer values in question\n",
    "    for i in split_answer:\n",
    "        if i in split_question:\n",
    "            match_count += 1\n",
    "    \n",
    "    # return the calculated count\n",
    "    return match_count / len(split_answer)\n",
    "    \n",
    "# count the words\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(count_terms, axis=1)\n",
    "\n",
    "# calculate the mean\n",
    "jeopardy['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that on average the answer shows up in the question around 6% of the time. This tells us that its quite difficult to deduce the answer from the question.\n",
    "\n",
    "## Recycled Questions\n",
    "\n",
    "Let's move to tackling our second question, where we need to find out how often new questions are repeats of older ones. Even though we can't completely answer this, because we only have about 10% of the full Jeopardy question dataset, but we can investigate it at least.\n",
    "\n",
    "We also should remove uninformative words (e.g stopwords) in order to better understand the question overlap. For this we will use `nltk` package to remove stopwords in the english language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7919779258717805"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# sorty jeopary values in ascending order\n",
    "jeopardy.sort_values('AirDate', inplace=True)\n",
    "\n",
    "# iterate through rows\n",
    "for i, row in jeopardy.iterrows():\n",
    "    # split the question by space\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    # remove words with less than 6 characters (keep the ones more than)\n",
    "    split_question = [word for word in split_question if word not in stop_words]\n",
    "    \n",
    "    # initialize count\n",
    "    match_count = 0\n",
    "    \n",
    "    # loop through words in split_question: count matches\n",
    "    for w in split_question:\n",
    "        if w in terms_used:\n",
    "            match_count += 1\n",
    "\n",
    "        # add words to terms used set\n",
    "        terms_used.add(w)\n",
    "            \n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "        \n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "jeopardy['question_overlap'] = question_overlap\n",
    "jeopardy['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results show that there is an 79% overlap between terms in new questions vs terms in old questions. This doesn't actually suggest us to actually study past questions, since it only looks at terms instead of full questions or even phrases. Only 79% of questions reoccur, which tells us that it might be a good idea to spend some time reviewing past questions to prepare for new ones.\n",
    "\n",
    "## Low value vs high value questions\n",
    "\n",
    "Nevertheless, we can also look at questions that pertain high value in terms of money. This strategy can help us earn more money when on Jeopardy.\n",
    "We can actually figure out which terms correspond to high-value questions using a chi-squared test. We'll first need to narrow down the questions into two categories:\n",
    "\n",
    "* Low value -- Any row where Value is less than 800.\n",
    "* High value -- Any row where Value is greater than 800.\n",
    "\n",
    "Let's write the code which will help us identify value pairs for terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find value \n",
    "def calculate_value(row):\n",
    "    value = 1 if row['clean_value'] > 800 else 0\n",
    "    return value\n",
    "\n",
    "# determine questions with high value\n",
    "jeopardy['high_value'] = jeopardy.apply(calculate_value, axis=1)\n",
    "\n",
    "# function to calculate value pairs (high, low count) for any word\n",
    "def calc_word(word):\n",
    "    high_count = 0\n",
    "    low_count = 0\n",
    "    \n",
    "    for index, row in jeopardy.iterrows():\n",
    "        q = row['clean_question'].split()\n",
    "        if word in q:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    \n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dictionary to hold the word and \n",
    "# counts of high and low value questions the term appears in\n",
    "observed_expected = {}\n",
    "\n",
    "# sample terms to run the value function on\n",
    "comparison_terms = list(terms_used)[:10]\n",
    "\n",
    "# calculate value pairs (high and low count) for each word in the sample\n",
    "for word in comparison_terms:\n",
    "    observed_expected[word] = calc_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'belushis': (1, 0),\n",
       " 'functions': (2, 2),\n",
       " 'brobdingnagian': (0, 1),\n",
       " 'daddyo': (1, 0),\n",
       " 'hrefhttpwwwjarchivecommedia20091117dj01jpg': (0, 1),\n",
       " 'vereen': (1, 0),\n",
       " '62foottall': (0, 1),\n",
       " 'galaxys': (0, 1),\n",
       " 'seducing': (1, 0),\n",
       " 'blaisdell': (0, 2)}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying chi-squared test\n",
    "\n",
    "Now that we've found the observed counts for a few terms, we can compute the expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total sum of high and low value questions\n",
    "high_value_count = jeopardy[\"high_value\"].sum()\n",
    "low_value_count = jeopardy.shape[0] - high_value_count\n",
    "\n",
    "# dictionary to hold chisquare and p-value for each term\n",
    "chi_squared = {}\n",
    "\n",
    "# loop through the dictionary \n",
    "for key, value in observed_expected.items():\n",
    "    \n",
    "    # calculate total value of high and low\n",
    "    total = value[0] + value[1]\n",
    "    \n",
    "    # calculate word occurence proportion across the dataset\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    \n",
    "    # find expected term for high and low value rows\n",
    "    high_exp, low_exp = total_prop * high_value_count, total_prop * low_value_count\n",
    "    \n",
    "    # calculate chi-squared statistic value and associated p-value\n",
    "    chi_squared[key] = chisquare(value, (high_exp, low_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'belushis': Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " 'functions': Power_divergenceResult(statistic=0.889754963322559, pvalue=0.3455437191483469),\n",
       " 'brobdingnagian': Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " 'daddyo': Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " 'hrefhttpwwwjarchivecommedia20091117dj01jpg': Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " 'vereen': Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " '62foottall': Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " 'galaxys': Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " 'seducing': Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " 'blaisdell': Power_divergenceResult(statistic=0.803925692253768, pvalue=0.3699222378079571)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the chi-squared test show that all of the sample terms we chose are not statistical significant. So far this shows that none of the terms above correspond to high value questions if we defined test significance acceptance level of $p=0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
