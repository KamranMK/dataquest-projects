{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing & Creating a Database\n",
    "\n",
    "In this project I will work with a file from [Major League Baseball](https://en.wikipedia.org/wiki/Major_League_Baseball) games from [Retrosheet](www.retrosheet.org). The goal of the project is to:\n",
    "\n",
    "* Import data into SQLite\n",
    "* Design a normalized database schema\n",
    "* Create tables for our schema\n",
    "* Insert data into our schema\n",
    "\n",
    "Retrosheet compiles detailed statistics on baseball games from the 1800s through to today. The main file we will be working from game_log.csv, has been produced by combining 127 separate CSV files from retrosheet, and has been pre-cleaned to remove some inconsistencies. The game log has hundreds of data points on each game which we will normalize into several separate tables using SQL, providing a robust database of game-level statistics.\n",
    "\n",
    "Since we are  trying to create a normalized database, so our focus should be:\n",
    "\n",
    "* Becoming familiar, at a high level, with the meaning of each column in each file.\n",
    "* Thinking about the relationships between columns within each file.\n",
    "* Thinking about the relationships between columns across different files.\n",
    "\n",
    "**Disclaimer:** This project is prepared as part of the guided projects on [dataquest](http://dataquest.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Setting the below options after we import pandas is recommendedâ€“ they will prevent the DataFrame output from being truncated, given the size of the main game log file. Let's also read in the data and explore it. To better understand columns we can use the following [game_log_fields.txt](data/game_log_fields.txt) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libs\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# set pandas options\n",
    "pd.set_option('max_columns', 180)\n",
    "pd.set_option('max_rows', 200000)\n",
    "pd.set_option('max_colwidth', 5000)\n",
    "\n",
    "# read dataset\n",
    "game_log = pd.read_csv('data/game_log.csv')\n",
    "park_codes = pd.read_csv('data/park_codes.csv')\n",
    "person_codes = pd.read_csv('data/person_codes.csv')\n",
    "team_codes = pd.read_csv('data/team_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Game Log\", game_log.shape)\n",
    "print(\"Park Codes\", park_codes.shape)\n",
    "print(\"Person Codes\", person_codes.shape)\n",
    "print(\"Team Codes\", team_codes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the above dataset, particularly let's look at what defensive position each number represents. We can observe that columns such `h_player_1_def_pos` and `v_player_9_def_pos` indicate the defensive positions of home player 1 and visiting player 9 respectively. The defensive positions are numbered (1-9). These are the defensive positions with their respective codes [(source)](https://en.wikipedia.org/wiki/Baseball_positions):\n",
    "\n",
    "Code. Position\n",
    "1. Pitcher\n",
    "2. Catcher\n",
    "3. First Baseman\n",
    "4. Second Baseman\n",
    "5. Third Baseman\n",
    "6. Shortstop\n",
    "7. Left Fielder\n",
    "8. Center Fielder\n",
    "9. Right Fielder\n",
    "\n",
    "The image below nicely visualizes these positions.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Baseball_positions.svg/300px-Baseball_positions.svg.png'>\n",
    "\n",
    "---\n",
    "Let's explore the league information. The columns 4-5, 7-8 indicate visiting team & home team leagues. We will look at those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_log.h_league.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_log.v_league.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the list of leagues and also notice that majority of games don't have information about their team leagues. The list of leagues and their interpretation:\n",
    "\n",
    "* AL - American League\n",
    "* AA - Double A League\n",
    "* FL - Florida State League\n",
    "* PL - Players League\n",
    "* UA - Union Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data into Sqlite\n",
    "\n",
    "To insert data into a normalized database we need to come up with a primary key for the game log table. Exploring the [Retrosheet site](https://www.retrosheet.org/eventfile.htm), we can find this data dictionary for their event files, which list every event within each game. This includes the following description:\n",
    "\n",
    "*__id__: Each game begins with a twelve character ID record which identifies the date, home team, and number of the game. For example, ATL198304080 should be read as follows. The first three characters identify the home team (the Braves). The next four are the year (1983). The next two are the month (April) using the standard numeric notation, 04, followed by the day (08). The last digit indicates if this is a single game (0), first game (1) or second game (2) if more than one game is played during a day, usually a double header The id record starts the description of a game thus ending the description of the preceding game in the file.*\n",
    "\n",
    "This is what we essentially need, where for our primary key we will use a composite key which has been described above. The key uses `date`, `home team` and `number of the game` to make up they composite key.\n",
    "\n",
    "Our next task is to import the data into SQLite. We will use pandas `DataFrame.to_sql()` function to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def run_query(q):\n",
    "    with sqlite3.connect('mlb.db') as conn:\n",
    "        return pd.read_sql(q, conn)\n",
    "    \n",
    "def run_command(q):\n",
    "    with sqlite3.connect('mlb.db') as conn:\n",
    "        conn.isolation_level = None\n",
    "        conn.execute(q)\n",
    "\n",
    "# show the tables\n",
    "def show_tables():\n",
    "    q = \"\"\"\n",
    "        SELECT name, type\n",
    "        FROM sqlite_master\n",
    "        WHERE type IN (\"table\",\"view\");\n",
    "    \"\"\"\n",
    "    return run_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe into sqlite database\n",
    "with sqlite3.connect('mlb.db') as conn:\n",
    "    game_log.to_sql('game_log', conn, if_exists='replace', index=False)\n",
    "    park_codes.to_sql('park_codes', conn, if_exists='replace', index=False)\n",
    "    person_codes.to_sql('person_codes', conn, if_exists='replace', index=False)\n",
    "    team_codes.to_sql('team_sql', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tables\n",
    "show_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a new column in `game_log` table called `game_id` which will using the key we discussed above. Composite key - `date`, `home team` and `number of the game`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'SELECT * FROM game_log LIMIT 5'\n",
    "run_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to add the new column\n",
    "q = 'ALTER TABLE game_log ADD COLUMN game_id VARCHAR'\n",
    "run_command(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to populate the column with concatenation\n",
    "q = 'UPDATE game_log SET game_id = h_name || date || number_of_game'\n",
    "run_command(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see the results\n",
    "q = 'SELECT * FROM game_log LIMIT 5'\n",
    "run_query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for Normalization Opportunities\n",
    "\n",
    "Through investigation of the tables above, we can spot multiple opportunities where we can normalize our data and eventually the database.\n",
    "\n",
    "__Repetition in Columns:__\n",
    "\n",
    "We can see in the below following segment of data that player information is spread out across columns (`id`, `name`, `off_pos`, `def_pos`). We can normalize this information by simply having a separate table with players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the above mentioned fragment\n",
    "q = '''\n",
    "SELECT v_player_1_id, v_player_1_name, v_player_1_def_pos,\n",
    "        v_player_2_id, v_player_2_name, v_player_2_def_pos\n",
    "FROM game_log LIMIT 10\n",
    "'''\n",
    "run_query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize the data we can convert into a table such as this.\n",
    "\n",
    "|id|name|def_pos|off_pos\n",
    "|---|---|---|---|\n",
    "|villj001|Jonathan Villar|5.0|1.0|\n",
    "|granc001|Curtis Granderson|8.0|1.0|\n",
    "|kendh001|Howie Kendrick|7.0|1.0|\n",
    "|jasoj001|John Jaso|3.0|1.0|\n",
    "|gordd002|Dee Gordon|4.0|1.0|\n",
    "|genns001|Scooter Gennett|4.0|2.0|\n",
    "|cabra002|Asdrubal Cabrera|6.0|2.0|\n",
    "|turnj001|Justin Turner|5.0|2.0|\n",
    "|polag001|Gregory Polanco|9.0|2.0|\n",
    "|telit001|Tomas Telis|2.0|2.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could transfer these into a new table from our `game_log` table but actually our `person_codes` table already contains the `id` and `name` of players. We could remove player name from our `game_log` table since we have player id's in the `person_codes` table.\n",
    "\n",
    "A similar to above approach could be used across our `game_log` and we can remove the following columns and simply keep player ids associated usually preceding these columns:\n",
    "\n",
    "* `hp_umpire_name`\n",
    "* `1b_umpire_name`\n",
    "* `2b_umpire_name`\n",
    "* `3b_umpire_name`\n",
    "* `lf_umpire_name`\n",
    "* `rf_umpire_name`\n",
    "* `v_manager_name`\n",
    "* `h_manager_name`\n",
    "* `winning_pitcher_name`\n",
    "* `losing_pitcher_name`\n",
    "* `saving_pitcher_name`\n",
    "* `winning_rbi_batter_id_name`\n",
    "* `v_starting_pitcher_name`\n",
    "* `h_starting_pitcher_name`\n",
    "\n",
    "And as discussed above all `v_player_{num}_name` and `h_player_{num}_name` columns would also be removed and associated id's kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'PRAGMA table_info(game_log);'\n",
    "# run_query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Redundant Data__\n",
    "\n",
    "We want to ensure that our database doesn't contain duplicate information, that is data which we can either find in another table or derive. One of those examples can be found in the `park_codes`.  We can check out the first few rows of the `park_codes` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'SELECT * FROM park_codes LIMIT 5'\n",
    "run_query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The start and end columns show the first and last games played at the park, however we will be able to derive this information by looking at the park information for each game. Similarly, the league information is going to be available elsewhere in our database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning a Normalized Schema\n",
    "\n",
    "In this section, we plan to prepare a database schema for our new database. We will use the [DbDesigner](https://www.dbdesigner.net/) tool to design a new schema. Below is the image of our schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
